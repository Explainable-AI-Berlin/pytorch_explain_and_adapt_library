<!DOCTYPE html>
<html>
<head>
    <title>PealDataset Class Documentation</title>
</head>
<body>
    <h1>PealDataset Class</h1>
    <p>
        This is the base class for all datasets in PEAL. It is a wrapper around
        <code>torch.utils.data.Dataset (nn.Module)</code>, which serves as the parent class for all datasets in PEAL.
    </p>

    <h2>Methods</h2>

    <h3><code>generate_contrastive_collage</code></h3>
    <p>
        <code>generate_contrastive_collage(self, x, x_counterfactual, target_confidence_goal, y_target, y_source, base_path, start_idx)</code><br>
        This function generates a collage of the input and the counterfactual.
    </p>
    <p><strong>Parameters:</strong></p>
    <ul>
        <li><code>x</code> (torch.tensor): The input batch.</li>
        <li><code>x_counterfactual</code> (torch.tensor): The counterfactual batch.</li>
        <li><code>target_confidence_goal</code>: The target confidence goal.</li>
        <li><code>y_target</code>: The target label.</li>
        <li><code>y_source</code>: The source label.</li>
        <li><code>base_path</code>: The base path.</li>
        <li><code>start_idx</code>: The starting index.</li>
    </ul>
    <p><strong>Returns:</strong></p>
    <ul>
        <li><code>torch.tensor</code>: The collage.</li>
    </ul>

    <h3><code>serialize_dataset</code></h3>
    <p>
        <code>serialize_dataset(self, output_dir, x_list, y_list, sample_names=None)</code><br>
        This function serializes the dataset to a given directory.
    </p>
    <p><strong>Parameters:</strong></p>
    <ul>
        <li><code>output_dir</code> (Path): The output directory.</li>
        <li><code>x_list</code> (list): The list of inputs.</li>
        <li><code>y_list</code> (list): The list of labels.</li>
        <li><code>sample_names</code> (list, optional): The list of sample names. Defaults to None.</li>
    </ul>

    <h3><code>project_to_pytorch_default</code></h3>
    <p>
        <code>project_to_pytorch_default(self, x)</code><br>
        This function maps processed data sample back to PyTorch default format.
    </p>
    <p><strong>Parameters:</strong></p>
    <ul>
        <li><code>x</code> (torch.tensor): The data sample in the processed format.</li>
    </ul>
    <p><strong>Returns:</strong></p>
    <ul>
        <li><code>torch.tensor</code>: The data sample in the PyTorch default format.</li>
    </ul>

    <h3><code>project_from_pytorch_default</code></h3>
    <p>
        <code>project_from_pytorch_default(self, x)</code><br>
        This function maps PyTorch default image to the processed format.
    </p>
    <p><strong>Parameters:</strong></p>
    <ul>
        <li><code>x</code> (torch.tensor): The data sample in the PyTorch default format.</li>
    </ul>
    <p><strong>Returns:</strong></p>
    <ul>
        <li><code>torch.tensor</code>: The data sample in the processed format.</li>
    </ul>

    <h3><code>track_generator_performance</code></h3>
    <p>
        <code>track_generator_performance(self, generator: Generator, batch_size=1)</code><br>
        This function tracks the performance of the generator.
    </p>
    <p><strong>Parameters:</strong></p>
    <ul>
        <li><code>generator</code> (Generator): The generator.</li>
        <li><code>batch_size</code> (int, optional): The batch size. Defaults to 1.</li>
    </ul>
    <p><strong>Returns:</strong></p>
    <ul>
        <li><code>{}</code>: An empty dictionary.</li>
    </ul>

    <h2>Example Usage</h2>

    <h3>Creating an Image2ClassDataset</h3>
    <p>First, import the required modules:</p>
    <pre><code>import os
import random
import copy
import torch
from torchvision.transforms import ToTensor
from PIL import Image</code></pre>

    <p>Next, define the configuration parameters for the dataset:</p>
    <pre><code>config = {
    "input_size": (64, 64),
    "output_size": ["class_1", "class_2", "class_3"],
    "split": [0.8, 0.9],
    "has_hints": True  # Set this to False if there are no hints/masks available
}</code></pre>

    <p>Instantiate the Image2ClassDataset:</p>
    <pre><code>root_dir = "/path/to/dataset"
mode = "train"
transform = ToTensor()
task_config = None
return_dict = False

dataset = Image2ClassDataset(root_dir, mode, config, transform, task_config, return_dict)</code></pre>
</body>
</html>