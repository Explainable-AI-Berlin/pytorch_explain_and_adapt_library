{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if peal not installed, but project downloaded locally\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# import basic libraries needed for sure and set the device depending on whether cuda is available or not\n",
    "import torch\n",
    "from peal.utils import request\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# set autoreload for more convinient development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# check and set that the right gpu is used\n",
    "if device == 'cuda':\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    !nvidia-smi\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    print('Currently used device: ' + str(os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= request('cuda_visible_devices', default = \"0\") \n",
    "    torch.cuda.set_device(int(os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "    import math\n",
    "    import nvidia_smi\n",
    "    nvidia_smi.nvmlInit()\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "    gigabyte_vram = info.total / math.pow(10, 9)\n",
    "    print(\"Total memory:\", gigabyte_vram)\n",
    "\n",
    "else:\n",
    "    gigabyte_vram = None\n",
    "\n",
    "#from IPython.core.debugger import set_trace #set_trace()\n",
    "\n",
    "confounder_type = request('confounder_type', default = 'copyrighttag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the celeba dataset needs to be downloaded and poised version needs to be created\n",
    "from peal.data.dataset_generators import ConfounderDatasetGenerator\n",
    "if not os.path.exists('datasets'):\n",
    "    os.makedirs('datasets')\n",
    "\n",
    "# Download the celeba dataset and move the images to folder CELEBA_ROOT\n",
    "CELEBA_IMG_DIR = request('CELEBA_IMG_DIR', default = '/home/space/datasets/celeba/img_align_celeba')\n",
    "\n",
    "# move the attribute labels to \n",
    "CELEBA_ATTRIBUTE_DIR = request('CELEBA_ATTRIBUTE_DIR', default = '/home/space/datasets/celeba/list_attr_celeba.txt')\n",
    "\n",
    "# TODO do this also for color and intensity\n",
    "cdg = ConfounderDatasetGenerator(\n",
    "    base_dataset_dir = CELEBA_IMG_DIR,\n",
    "    dataset_name = 'celeba_' + confounder_type,\n",
    "    label_dir = CELEBA_ATTRIBUTE_DIR,\n",
    "    delimiter = ' ',\n",
    "    confounder_type = confounder_type\n",
    ")\n",
    "cdg.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets\n",
    "import copy\n",
    "from peal.data.datasets import get_datasets\n",
    "from peal.utils import load_yaml_config\n",
    "unpoised_dataset_config = load_yaml_config('$PEAL/configs/data/isblond_confounder_celeba.yaml')\n",
    "unpoised_dataset_train, unpoised_dataset_val, unpoised_dataset_test = get_datasets(\n",
    "    config = unpoised_dataset_config,\n",
    "    base_dir = 'datasets/celeba_' + confounder_type\n",
    ")\n",
    "poised_datasets = {}\n",
    "poisoning_degrees = request('poisoning_degrees', ['100', '95', '90', '85', '80'])\n",
    "for poisoning_degree in poisoning_degrees:\n",
    "    print(poisoning_degree)\n",
    "    dataset_config = copy.deepcopy(unpoised_dataset_config)\n",
    "    dataset_config['num_samples'] = int(unpoised_dataset_config['num_samples'] / 2)\n",
    "    dataset_config['confounder_probability'] = int(poisoning_degree) / 100\n",
    "    poised_datasets[poisoning_degree] = get_datasets(\n",
    "        config = dataset_config,\n",
    "        base_dir = 'datasets/celeba_' + confounder_type\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to train your own initial student model\n",
    "from peal.architectures.models import ImgEncoderDecoderModel\n",
    "from peal.training.trainers import ModelTrainer\n",
    "\n",
    "for poisoning_degree in poisoning_degrees:\n",
    "    poised_dataset_train, poised_dataset_val, poised_dataset_test = poised_datasets[poisoning_degree]\n",
    "    student_config = load_yaml_config('$PEAL/configs/models/celeba_isblond_classifier.yaml')\n",
    "    student_config['data'] = poised_dataset_train.config\n",
    "\n",
    "    # create and traing student model\n",
    "    student = ImgEncoderDecoderModel(student_config).to(device)\n",
    "    student_trainer = ModelTrainer(\n",
    "        config = student_config, \n",
    "        model = student, \n",
    "        datasource = (poised_dataset_train, poised_dataset_val),\n",
    "        model_name = 'celeba_poised' + poisoning_degree + '_isblond_' + confounder_type + '_classifier'\n",
    "    )\n",
    "    student_trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose whether to approximate the results by always using strongest poised generator\n",
    "use_predefined_generator = request('use_predefined_generator', True)\n",
    "if use_predefined_generator:\n",
    "    generator_path = request(\n",
    "        'generator_path',\n",
    "        'peal_runs/celeba_poised100_' + confounder_type + '_generator/model.cpl'\n",
    "    )\n",
    "    generator = torch.load(generator_path).to(device)\n",
    "\n",
    "else:\n",
    "    generator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_type = request('teacher_type', 'train')\n",
    "if teacher_type == 'train':\n",
    "    # if you want to train and use new model for knowledge distillation\n",
    "    from peal.architectures.models import ImgEncoderDecoderModel\n",
    "    from peal.training.trainers import ModelTrainer\n",
    "    teacher_config = load_yaml_config('$PEAL/configs/models/celeba_isblond_classifier.yaml')\n",
    "    teacher_config['data'] = unpoised_dataset_train.config\n",
    "\n",
    "    # create and train teacher model\n",
    "    teacher = ImgEncoderDecoderModel(teacher_config).to(device)\n",
    "    teacher_trainer = ModelTrainer(\n",
    "        config = teacher_config,\n",
    "        model = teacher, \n",
    "        datasource = (unpoised_dataset_train, unpoised_dataset_val),\n",
    "        model_name = request('teacher_model_name', 'celeba_unpoised_isblond_' + confounder_type + '_classifier'),\n",
    "        gigabyte_vram = gigabyte_vram\n",
    "    )\n",
    "    teacher_trainer.fit()\n",
    "    teacher_type = 'oracle'\n",
    "\n",
    "elif teacher_type == 'load':\n",
    "    # if you want to use existing model for knowledge distillation\n",
    "    teacher_path = request('teacher_path', 'peal_runs/celeba_unpoised_isblond_' + confounder_type + '_classifier/model.cpl')\n",
    "    teacher = torch.load(teacher_path).to(device)\n",
    "    teacher_type = 'oracle'\n",
    "\n",
    "else:\n",
    "    # if you want to teach the model yourself with the web interface\n",
    "    teacher = teacher_type\n",
    "    teacher_type = teacher.split('@')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create counterfactual mode\n",
    "from peal.adaptors.counterfactual_knowledge_distillation import CounterfactualKnowledgeDistillation\n",
    "for it, poisoning_degree in enumerate(poisoning_degrees):\n",
    "    print(poisoning_degree)\n",
    "    student_path = os.path.join(\n",
    "        'peal_runs',\n",
    "        'celeba_poised' + poisoning_degree + '_isblond_' + confounder_type + '_classifier'\n",
    "    )\n",
    "    student = torch.load(\n",
    "        os.path.join(student_path, 'model.cpl'),\n",
    "        map_location = device\n",
    "    )\n",
    "    cfkd = CounterfactualKnowledgeDistillation(\n",
    "        student = student,\n",
    "        datasource = (\n",
    "            poised_datasets[poisoning_degree][0],\n",
    "            poised_datasets[poisoning_degree][1],\n",
    "            unpoised_dataset_test\n",
    "        ),\n",
    "        output_size = 2,\n",
    "        teacher = teacher,\n",
    "        generator = generator,\n",
    "        base_dir = 'peal_runs/celeba_poised' + poisoning_degree + '_isblond_' + confounder_type + '_classifier/cfkd_oracle',\n",
    "        gigabyte_vram = gigabyte_vram\n",
    "    )\n",
    "    cfkd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "# perform P-Clark and measure test accuracies on unpoised dataset\n",
    "from peal.adaptors.class_artifact_compensation import ClassArtifactCompensation\n",
    "for it, poisoning_degree in enumerate(poisoning_degrees):\n",
    "    print(poisoning_degree)\n",
    "    student_path = os.path.join('peal_runs','celeba_poised' + poisoning_degree + '_isblond_' + confounder_type + '_classifier')\n",
    "    student = torch.load(\n",
    "        os.path.join(student_path, 'model.cpl'),\n",
    "        map_location = device\n",
    "    )\n",
    "    pclarc = ClassArtifactCompensation(\n",
    "        student = student,\n",
    "        datasource =(\n",
    "            poised_datasets[poisoning_degree][0],\n",
    "            poised_datasets[poisoning_degree][1],\n",
    "            unpoised_dataset_test\n",
    "        ),\n",
    "        output_size = 2,\n",
    "        base_dir = os.path.join(student_path, 'pclarc_' + teacher_type),\n",
    "        teacher = teacher,\n",
    "        gigabyte_vram = gigabyte_vram,\n",
    "        overwrite = False\n",
    "    )\n",
    "    pclarc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the test accuracies on the unpoised dataset\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from peal.data.dataloaders import get_dataloader\n",
    "accuracies = []\n",
    "accuracies_pclarc = []\n",
    "accuracies_cfkd = []\n",
    "student_config = load_yaml_config('$PEAL/configs/models/celeba_isblond_classifier.yaml')\n",
    "student_config['training']['test_batch_size'] = 10\n",
    "unpoised_dataloader_test = get_dataloader(\n",
    "    dataset = unpoised_dataset_test,\n",
    "    training_config = student_config['training'],\n",
    "    mode = 'test',\n",
    "    task_config = student_config['task']\n",
    ")\n",
    "for poisoning_degree in poisoning_degrees:\n",
    "    student_name = 'celeba_poised' + poisoning_degree + '_isblond_' + confounder_type + '_classifier'\n",
    "    student = torch.load(\n",
    "        os.path.join(\n",
    "            'peal_runs',\n",
    "            student_name,\n",
    "            'model.cpl'\n",
    "        ),\n",
    "        map_location = device\n",
    "    )\n",
    "    '''student_pclarc = torch.load(\n",
    "        os.path.join(\n",
    "            'peal_runs',\n",
    "            'celeba_poised' + poisoning_degree + '_isblond_' + confounder_type + '_classifier',\n",
    "            'pclarc_human', \n",
    "            'model.cpl'\n",
    "        ),\n",
    "        map_location = device\n",
    "    )'''\n",
    "    student_pclarc = student\n",
    "    student_cfkd = torch.load(\n",
    "        os.path.join(\n",
    "            'peal_runs',\n",
    "            'celeba_poised' + poisoning_degree + '_isblond_' + confounder_type + '_classifier',\n",
    "            'cfkd_oracle',\n",
    "            'model.cpl'\n",
    "        ),\n",
    "        map_location = device\n",
    "    )\n",
    "    correct = 0\n",
    "    correct_pclarc = 0\n",
    "    correct_cfkd = 0\n",
    "    with tqdm( enumerate(unpoised_dataloader_test)) as pbar:\n",
    "        for it, (X, y) in pbar:\n",
    "            y_pred = student(X.to(device)).argmax(-1).to('cpu')\n",
    "            correct += float(torch.sum(y_pred == y))\n",
    "            y_pred_plarc = student_pclarc(X.to(device)).argmax(-1).to('cpu')\n",
    "            correct_pclarc += float(torch.sum(y_pred_plarc == y))\n",
    "            y_pred_cfkd = student_cfkd(X.to(device)).argmax(-1).to('cpu')\n",
    "            correct_cfkd += float(torch.sum(y_pred_cfkd == y))\n",
    "            pbar.set_description('poisoning_degree: ' + poisoning_degree + ', it: ' + str(it))\n",
    "    \n",
    "    accuracy = correct / unpoised_dataset_test.__len__()\n",
    "    accuracies.append(accuracy)\n",
    "    accuracy_pclarc = correct_pclarc / unpoised_dataset_test.__len__()\n",
    "    accuracies_pclarc.append(accuracy_pclarc)\n",
    "    accuracy_cfkd = correct_cfkd / unpoised_dataset_test.__len__()\n",
    "    accuracies_cfkd.append(accuracy_cfkd)\n",
    "    with open(\n",
    "        os.path.join('peal_runs', student_name, 'results.json'),\n",
    "        'w'\n",
    "    ) as result_file:\n",
    "        json.dump(\n",
    "            {'accuracy' : accuracy, 'accuracy_pclarc' : accuracy_pclarc, 'accuracy_cfkd' : accuracy_cfkd},\n",
    "            result_file,\n",
    "            indent=4\n",
    "        )\n",
    "# 0.6, 0.7, 0.8, 0.9, 0.95, 0.99\n",
    "# [0.91025, 0.901, 0.864, 0.819, 0.7635, 0.51375]\n",
    "# 0.56\n",
    "# > 0.8\n",
    "# 1.0, 0.95, 0.9, 0.85, 0.8\n",
    "# copyrighttag: 0.5, 0.7635, 0.819, 0.86875, 0.864\n",
    "# intensity: 0.5045, 0.807, 0.84925, 0.86125, 0.887\n",
    "# color: 0.502, 0.71075, 0.8295, 0.868, 0.89425\n",
    "print(accuracies)\n",
    "print(accuracies_pclarc)\n",
    "print(accuracies_cfkd)\n",
    "\n",
    "# TODO Visualize curves in nice matplotlib plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracies_cfkd = [0.65, 0.82, 0.84, 0.894, 0.897]\n",
    "accuracies_cfkd = [0.84, 0.82, 0.84, 0.894, 0.897]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copyright tag\n",
    "oracle_test_accuracy = 0.916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intensity\n",
    "oracle_test_accuracy = 0.922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color\n",
    "oracle_test_accuracy = 0.9155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#x1 = [0.85, 0.9, 0.95, 1.0]\n",
    "#y1 = [0.86875, 0.819, 0.7635, 0.5]\n",
    "#y2 = [0.88, 0.85, 0.82, 0.74]\n",
    "#y3 = [0.86875, 0.83, 0.78, 0.56]\n",
    "#x1 = [0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "x1 = [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "y1 = accuracies[::-1]\n",
    "y2 = accuracies_cfkd[::-1]\n",
    "y3 = accuracies_pclarc[::-1]\n",
    "\n",
    "\n",
    "confounder_stronger = 1 - 2 * (1 - oracle_test_accuracy)\n",
    "\n",
    "plt.plot(x1, y1, label='uncorrected', color='red')\n",
    "plt.plot(x1, y2, label='cfkd', color='green')\n",
    "#plt.plot(x1, y3, label='pclarc', color='blue')\n",
    "\n",
    "plt.axvline(x=confounder_stronger, linestyle='--', color='gray', label='Confounder is stronger feature')\n",
    "plt.axhline(y=oracle_test_accuracy, linestyle='--', color='purple', label='Oracle Model')\n",
    "plt.axhline(y=0.5, linestyle='--', color='black', label='Random')\n",
    "\n",
    "plt.xlabel('Correlation Confounder & Class in Training')\n",
    "plt.ylabel('Accuracy on Test Set without Correlation')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#x1 = [0.85, 0.9, 0.95, 1.0]\n",
    "#y1 = [0.86875, 0.819, 0.7635, 0.5]\n",
    "#y2 = [0.88, 0.85, 0.82, 0.74]\n",
    "#y3 = [0.86875, 0.83, 0.78, 0.56]\n",
    "#x1 = [0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "x1 = [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "y1 = accuracies[::-1]\n",
    "y2 = accuracies_cfkd[::-1]\n",
    "y3 = accuracies_pclarc[::-1]\n",
    "\n",
    "oracle_test_accuracy = 0.91\n",
    "confounder_stronger = 1 - 2 * (1 - oracle_test_accuracy)\n",
    "\n",
    "plt.plot(x1, y1, label='uncorrected', color='red')\n",
    "plt.plot(x1, y2, label='cfkd', color='green')\n",
    "plt.plot(x1, y3, label='pclarc', color='blue')\n",
    "\n",
    "plt.axvline(x=confounder_stronger, linestyle='--', color='gray', label='Confounder is stronger feature')\n",
    "plt.axhline(y=oracle_test_accuracy, linestyle='--', color='purple', label='Oracle Model')\n",
    "plt.axhline(y=0.5, linestyle='--', color='black', label='Random')\n",
    "\n",
    "plt.xlabel('Correlation Confounder & Class in Training')\n",
    "plt.ylabel('Accuracy on Test Set without Correlation')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Validation Accuracy'\n",
    "y1 = [0.97, 0.97, 0.95, 0.93, 0.92, 0.96]\n",
    "y2 = [0.97, 0.96, 0.94, 0.92, 0.91, 0.91]\n",
    "y3 = [0.97, 0.97, 0.96, 0.95, 0.94, 0.92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Unpoised Test Accuracy'\n",
    "y1 = [0.54, 0.58, 0.70, 0.78, 0.78, 0.78]\n",
    "y2 = [0.54, 0.59, 0.73, 0.79, 0.81, 0.82]\n",
    "y3 = [0.54, 0.58, 0.71, 0.78, 0.79, 0.80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Feedback Accuracy'\n",
    "y1 = [0.29, 0.44, 0.49, 0.4, 0.29, 0.33]\n",
    "y2 = [0.05, 0.13, 0.21, 0.30, 0.35, 0.41]\n",
    "y3 = [0.34, 0.45, 0.49, 0.54, 0.55, 0.56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Validation Accuracy'\n",
    "y1 = [0.97, 0.97, 0.95]\n",
    "y2 = [0.97, 0.95, 0.94]\n",
    "y3 = [0.97, 0.96, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Unpoised Test Accuracy'\n",
    "y1 = [0.54, 0.58, 0.70]\n",
    "y2 = [0.54, 0.60, 0.60]\n",
    "y3 = [0.54, 0.57, 0.63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Feedback Accuracy'\n",
    "y1 = [0.29, 0.44, 0.49]\n",
    "y2 = [0.04, 0.12, 0.23]\n",
    "y3 = [0.05, 0.18, 0.34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = range(3)\n",
    "\n",
    "plt.plot(x1, y1, label='oracle', color='red')\n",
    "plt.plot(x1, y2, label='SpRAy', color='green')\n",
    "plt.plot(x1, y3, label='human', color='blue')\n",
    "\n",
    "plt.xlabel('Num Iterations')\n",
    "plt.ylabel(label)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates plot for cancer tissue classifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "oracle_test_accuracy = 0.94\n",
    "poised_accuracy = 0.65\n",
    "y1 = [0.31, 0.57, 0.44, 0.27, 0.71, 0.51]\n",
    "y2 = [0.99, 0.94, 0.94, 0.58, 0.98, 0.97]\n",
    "y3 = [0.65, 0.69, 0.71, 0.52, 0.83, 0.76]\n",
    "x1 = range(6)\n",
    "\n",
    "plt.plot(x1, y1, label='Feedback Accuracy', color='red')\n",
    "plt.plot(x1, y2, label='Validation Accuracy', color='green')\n",
    "plt.plot(x1, y3, label='Unpoised Test Accuracy', color='blue')\n",
    "\n",
    "plt.axhline(y=oracle_test_accuracy, linestyle='--', color='purple', label='Oracle Model')\n",
    "plt.axhline(y=poised_accuracy, linestyle='--', color='black', label='Poised accuracy')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = '/home/sidney/workspace/pytorch_global_explanations_library'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import models\n",
    "    \n",
    "student_cfkd = torch.load(\n",
    "    '/home/sidney/workspace/pytorch_global_explanations_library/runs/celeba_isblond_hardconfounder_classifier/explanations/counterfactual_explanation_machine/4/finetuned_model/final_model.cpl'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peal.architectures.interfaces import InvertibleGenerator\n",
    "from peal.architectures.coupling_layers import gaussian_log_p\n",
    "\n",
    "class GlowGenerator(InvertibleGenerator):\n",
    "    def __init__(self, glow_model):\n",
    "        super().__init__()\n",
    "        self.glow_model = glow_model\n",
    "    \n",
    "    def encode(self, x):\n",
    "        log_p_sum, logdet, z_outs = self.glow_model.forward(x)\n",
    "        return z_outs\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.glow_model.reverse(z, reconstruct = True)\n",
    "    \n",
    "    def log_prob_z(self, z):\n",
    "        log_probs = []\n",
    "\n",
    "        for it, block in enumerate(self.glow_model.blocks):\n",
    "            zero = torch.zeros_like(z[it])\n",
    "            mean, log_sd = block.prior(zero).chunk(2, 1)\n",
    "            log_p = gaussian_log_p(z[it], mean, log_sd)\n",
    "            log_probs.append(torch.flatten(log_p, start_dim = 1).sum(1))\n",
    "        \n",
    "        log_p_sum = torch.sum(torch.stack(log_probs, dim = 0), dim = 0)\n",
    "\n",
    "        n_pixel = 64 * 64 * 3\n",
    "        log_p = log_p_sum - 5 * n_pixel\n",
    "        return - torch.tensor(log_p / (math.log(2) * n_pixel))\n",
    "\n",
    "module_path = '/home/sidney/workspace/pytorch_global_explanations_library'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import models\n",
    "    \n",
    "glow = torch.load(\n",
    "    '/home/sidney/workspace/pytorch_global_explanations_library/runs/celeba_with_copyright_tag_generator/final_model.pt'\n",
    ").module.to(device)\n",
    "generator = GlowGenerator(glow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'celeba_poised' + poisoning_degrees[0] + '_isblond_' + confounder_type + '_classifier'\n",
    "student = torch.load(\n",
    "    os.path.join('peal_runs', model_name, 'model.cpl'),\n",
    "    map_location = device\n",
    ")\n",
    "'''student_cfkd = torch.load(\n",
    "    os.path.join('peal_runs',model_name, 'cfkd_new3', 'model.cpl'),\n",
    "    map_location = device\n",
    ")'''\n",
    "student_pclarc = torch.load(\n",
    "    os.path.join('peal_runs',model_name, 'pclarc', 'model.cpl'),\n",
    "    map_location = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peal.visualization.model_comparison import create_comparison\n",
    "\n",
    "unpoised_dataset_test.task_config = {'selection' : [], 'criterions' : []}\n",
    "\n",
    "for poisoning_degree in poisoning_degrees:\n",
    "    img = create_comparison(\n",
    "        dataset = unpoised_dataset_test,\n",
    "        criterions = {\n",
    "            'blond' : lambda X, y: int(y[unpoised_dataset_test.attributes.index('Blond_Hair')]),\n",
    "            #'confounder' : lambda X, y: int(y[unpoised_dataset_test.attributes.index('Confounder')]),\n",
    "            'uncorrected' : lambda X, y: int(\n",
    "                student(X.unsqueeze(0).to(device)).squeeze(0).cpu().argmax()\n",
    "            ),\n",
    "            'cfkd' : lambda X, y: int(\n",
    "                student_cfkd(X.unsqueeze(0).to(device)).squeeze(0).cpu().argmax()\n",
    "            ),\n",
    "            'pclarc' : lambda X, y: int(student_pclarc(X.unsqueeze(0).to(device)).squeeze(0).cpu().argmax())\n",
    "        },\n",
    "        columns = {            \n",
    "            'Counterfactual\\nExplanation' : ['cf', student, 'uncorrected'],\n",
    "            'CFKD\\ncorrected' : ['cf', student_cfkd, 'cfkd'],\n",
    "            'LRP\\nExplanation' : ['lrp', student, 'uncorrected'],\n",
    "            'PClarC\\ncorrected' : ['lrp', student_pclarc, 'pclarc'],\n",
    "        },\n",
    "        score_reference_idx = 1,\n",
    "        generator = generator,\n",
    "        device = device,\n",
    "        max_samples = 50\n",
    "    )\n",
    "    #img.show()\n",
    "    img.save('qualitative_results.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peal_env",
   "language": "python",
   "name": "peal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
