{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if peal not installed, but project downloaded locally\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# import basic libraries needed for sure and set the device depending on whether cuda is available or not\n",
    "import torch\n",
    "from peal.utils import request\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# set autoreload for more convinient development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# check and set that the right gpu is used\n",
    "if device == 'cuda':\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    !nvidia-smi\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    print('Currently used device: ' + str(os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= request('cuda_visible_devices', default = \"0\")\n",
    "    torch.cuda.set_device(int(os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "    import math\n",
    "    import nvidia_smi\n",
    "    nvidia_smi.nvmlInit()\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "    gigabyte_vram = info.total / math.pow(10, 9)\n",
    "    print(\"Total memory:\", gigabyte_vram)\n",
    "\n",
    "else:\n",
    "    gigabyte_vram = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the stain normed and the unnormed dataset from https://zenodo.org/record/1214456#.Y-pAToOYVhE\n",
    "\n",
    "base_dir = '/home/sidney/workspace/explain_and_adapt_library/notebooks/datasets'\n",
    "from PIL import Image\n",
    "\n",
    "for dataset_type in ['normalized']: #, 'no_norm']:\n",
    "    if dataset_type == 'no_norm':\n",
    "        appendix = '-NONORM'\n",
    "    \n",
    "    else:\n",
    "        appendix = ''\n",
    "        \n",
    "    raw_data_dir = base_dir + '/cancer_tissue_raw_' + dataset_type + '/NCT-CRC-HE-100K' + appendix\n",
    "    output_dir = 'datasets/cancer_tissue_' + dataset_type\n",
    "    os.makedirs(output_dir)\n",
    "    # move the MUS and the STR classes to a new folder and convert them to .png images\n",
    "    for folder_name in ['MUS', 'STR']:\n",
    "        os.makedirs(os.path.join(output_dir, folder_name))\n",
    "        for img_name in os.listdir(os.path.join(raw_data_dir, folder_name)):\n",
    "            img = Image.open(os.path.join(raw_data_dir, folder_name, img_name))\n",
    "            img.save(os.path.join(output_dir, folder_name, img_name[:-4] + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets\n",
    "from peal.data.datasets import get_datasets\n",
    "from peal.utils import load_yaml_config\n",
    "import copy\n",
    "unpoised_dataset_config = load_yaml_config('$PEAL/configs/data/cancer_tissue.yaml')\n",
    "dataset_base_dir = request('dataset_base_dir', 'datasets/cancer_tissue_no_norm')\n",
    "unpoised_dataset_train, unpoised_dataset_val, unpoised_dataset_test = get_datasets(\n",
    "    config = unpoised_dataset_config,\n",
    "    base_dir = dataset_base_dir\n",
    ")\n",
    "\n",
    "# create a copy of the dataset config that will be poised in the next steps\n",
    "poised_dataset_config = copy.deepcopy(unpoised_dataset_config)\n",
    "\n",
    "# throw away all samples that are blond and with copyright tag or neither blond nor with a copyright tag\n",
    "poised_dataset_config['num_samples'] = int(unpoised_dataset_config['num_samples']  / 2)\n",
    "\n",
    "confounder_probability = request('confounder_probability', '100')\n",
    "poised_dataset_config['confounder_probability'] = float(confounder_probability) / 100\n",
    "\n",
    "# create dataset based changed data config\n",
    "poised_dataset_train, poised_dataset_val, poised_dataset_test = get_datasets(\n",
    "    config = poised_dataset_config,\n",
    "    base_dir = dataset_base_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find staining of images\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "base_dir = '/home/sidney/workspace/explain_and_adapt_library/notebooks/datasets/cancer_tissue_no_norm'\n",
    "sample_list = []\n",
    "class_names = ['MUS', 'STR']\n",
    "for y in range(2):\n",
    "    class_name = class_names[y]\n",
    "    for idx, file_name in enumerate(os.listdir(os.path.join(base_dir, class_name))):\n",
    "        if idx % 100 == 0:\n",
    "            print(str(idx) + ' / ' + str(len(os.listdir(os.path.join(base_dir, class_name)))))\n",
    "        # TODO by class\n",
    "        #idx = int(np.random.randint(0, len(poised_dataset_train)))\n",
    "        #X, y = poised_dataset_train[idx]\n",
    "        X = np.array(Image.open(os.path.join(base_dir, class_name, file_name)), dtype=np.float32) / 255\n",
    "        img = np.expand_dims(X, 0)\n",
    "        patches = img\n",
    "        def RGB2OD(image:np.ndarray) -> np.ndarray:\n",
    "            mask = (image == 0)\n",
    "            image[mask] = 1\n",
    "            return np.maximum(-1 * np.log(image), 1e-5)\n",
    "\n",
    "        OD_raw = RGB2OD(np.stack(patches).reshape(-1,3))\n",
    "        OD = (OD_raw[(OD_raw > 0.15).any(axis=1), :])\n",
    "\n",
    "        _, eigenVectors = np.linalg.eigh(np.cov(OD, rowvar=False))\n",
    "        eigenVectors = eigenVectors[:, [2, 1]] # strip off residual stain component\n",
    "\n",
    "        if eigenVectors[0, 0] < 0: eigenVectors[:, 0] *= -1\n",
    "        if eigenVectors[0, 1] < 0: eigenVectors[:, 1] *= -1\n",
    "        T_hat = np.dot(OD, eigenVectors)\n",
    "\n",
    "        phi = np.arctan2(T_hat[:, 1], T_hat[:, 0])\n",
    "        min_Phi = np.percentile(phi, 1)\n",
    "        max_Phi = np.percentile(phi, 99)\n",
    "\n",
    "        v1 = np.dot(eigenVectors, np.array([np.cos(min_Phi), np.sin(min_Phi)]))\n",
    "        v2 = np.dot(eigenVectors, np.array([np.cos(max_Phi), np.sin(max_Phi)]))\n",
    "        if v1[0] > v2[0]:\n",
    "            stainVectors = np.array([v1, v2])\n",
    "        else:\n",
    "            stainVectors = np.array([v2, v1])\n",
    "\n",
    "        sample_list.append([os.path.join(class_name, file_name), X, y, stainVectors, OD_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hematoxylin_intensities_by_class = [[], []]\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a, axis = -1) * np.linalg.norm(b))\n",
    "\n",
    "sample_list_new = []\n",
    "for sample in sample_list:\n",
    "    path, X, y, stainVectors, OD_raw = sample\n",
    "    similarities_0 = cosine_similarity(OD_raw, stainVectors[0])\n",
    "    similarities_1 = cosine_similarity(OD_raw, stainVectors[1])\n",
    "    hematoxylin_greater_mask = similarities_0 > similarities_1\n",
    "    X_intensities = np.linalg.norm(X, axis = -1).flatten()\n",
    "    X_masked_intensities = X_intensities * hematoxylin_greater_mask\n",
    "    stable_maximum = np.percentile(X_masked_intensities, 99)\n",
    "    hematoxylin_intensities_by_class[y].append(stable_maximum)\n",
    "    sample_list_new.append([path, X, y, stainVectors, OD_raw, stable_maximum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/sidney/workspace/explain_and_adapt_library/notebooks/datasets/cancer_tissue_no_norm'\n",
    "intensity_median = np.percentile(\n",
    "    np.concatenate([hematoxylin_intensities_by_class[0],hematoxylin_intensities_by_class[1]]),\n",
    "    50\n",
    ")\n",
    "def check(sample, has_attribute, has_confounder):\n",
    "    return sample[2] == has_attribute and int((sample[-1] > intensity_median)) == has_confounder\n",
    "\n",
    "lines_out = ['ImgPath,Cancer,Confounder,ConfounderStrength']\n",
    "idxs = np.zeros([2, 2], dtype=np.int32)\n",
    "for sample_idx in range(18000):\n",
    "    if sample_idx % 100 == 0:\n",
    "        print(sample_idx)\n",
    "        open(os.path.join(base_dir, 'data.csv'), 'w').write('\\n'.join(lines_out))\n",
    "\n",
    "    has_attribute = int(sample_idx  % 4 == 0 or sample_idx  % 4 == 1)\n",
    "    has_confounder = int(sample_idx % 2 == 0)\n",
    "\n",
    "    while not check(sample_list_new[int(idxs[has_attribute][has_confounder])], has_attribute, has_confounder):\n",
    "        idxs[has_attribute][has_confounder] += 1\n",
    "    \n",
    "    sample = sample_list_new[idxs[has_attribute][has_confounder]]\n",
    "    lines_out.append(sample[0] + ',' + str(has_attribute) + ',' + str(has_confounder) + ',' + str(sample[-1]))\n",
    "    print(str(has_attribute) + ' ' + str(has_confounder) + ' ' + str(idxs[has_attribute][has_confounder]))\n",
    "    idxs[has_attribute][has_confounder] += 1\n",
    "\n",
    "open(os.path.join(base_dir, 'data.csv'), 'w').write('\\n'.join(lines_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(hematoxylin_intensities_by_class[0]))\n",
    "print(np.percentile(hematoxylin_intensities_by_class[0], 25))\n",
    "print(np.percentile(hematoxylin_intensities_by_class[0], 50))\n",
    "print(np.percentile(hematoxylin_intensities_by_class[0], 75))\n",
    "print(np.max(hematoxylin_intensities_by_class[0]))\n",
    "print(np.min(hematoxylin_intensities_by_class[1]))\n",
    "print(np.percentile(hematoxylin_intensities_by_class[1], 25))\n",
    "print(np.percentile(hematoxylin_intensities_by_class[1], 50))\n",
    "print(np.percentile(hematoxylin_intensities_by_class[1], 75))\n",
    "print(np.max(hematoxylin_intensities_by_class[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train_student = request('is_train_student', True)\n",
    "if is_train_student:\n",
    "    from peal.architectures.models import ImgEncoderDecoderModel\n",
    "    from peal.training.trainers import ModelTrainer\n",
    "    student_config = load_yaml_config('$PEAL/configs/models/cancer_tissue_classifier.yaml')\n",
    "    student_config['data'] = poised_dataset_train.config\n",
    "    student = ImgEncoderDecoderModel(student_config).to(device)\n",
    "    student_trainer = ModelTrainer(\n",
    "        config = student_config, \n",
    "        model = student, \n",
    "        datasource = (poised_dataset_train, poised_dataset_val),\n",
    "        model_name = request('student_name', 'cancer_tissue_classifier')\n",
    "    )\n",
    "    student_trainer.fit()\n",
    "\n",
    "else:\n",
    "    # or if you want to load your initial student model\n",
    "    student_path = request('student_path', 'peal_runs/cancer_tissue_classifier/model.cpl')\n",
    "    student = torch.load(student_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_type = request('teacher_type', 'train')\n",
    "if teacher_type == 'train':\n",
    "    from peal.architectures.models import ImgEncoderDecoderModel\n",
    "    from peal.training.trainers import ModelTrainer\n",
    "    teacher_config = load_yaml_config('$PEAL/configs/models/cancer_tissue_classifier.yaml')\n",
    "    teacher_config['data'] = poised_dataset_train.config\n",
    "    teacher = ImgEncoderDecoderModel(teacher_config).to(device)\n",
    "    teacher_trainer = ModelTrainer(\n",
    "        config = student_config, \n",
    "        model = student, \n",
    "        datasource = (unpoised_dataset_train, unpoised_dataset_val),\n",
    "        model_name = request('teacher_name', 'cancer_tissue_classifier_unpoised')\n",
    "    )\n",
    "    teacher_trainer.fit()\n",
    "    teacher_type = 'oracle'\n",
    "\n",
    "elif teacher_type == 'load':\n",
    "    # if you want to use existing model for knowledge distillation\n",
    "    teacher_path = request('teacher_path', 'peal_runs/cancer_tissue_classifier_unpoised/model.cpl')\n",
    "    teacher = torch.load(teacher_path).to(device)\n",
    "    teacher_type = 'oracle'\n",
    "\n",
    "else:\n",
    "    teacher = teacher_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train_generator = request('is_train_generator', True)\n",
    "if is_train_generator:\n",
    "    # if you want the generator getting trained from scratch\n",
    "    from peal.architectures.generators import Glow\n",
    "    from peal.training.trainers import ModelTrainer\n",
    "    generator_config = load_yaml_config('$PEAL/configs/models/default_generator.yaml')\n",
    "    generator_config['data'] = poised_dataset_train.config\n",
    "    generator = Glow(generator_config).to(device)\n",
    "\n",
    "    generator_trainer = ModelTrainer(\n",
    "        config = generator_config, \n",
    "        model = generator,\n",
    "        datasource = (poised_dataset_train, poised_dataset_val),\n",
    "        model_name = request('generator_model_name', 'cancer_tissue_generator'),\n",
    "        gigabyte_vram = gigabyte_vram / 2\n",
    "    )\n",
    "    generator_trainer.fit()\n",
    "\n",
    "else:\n",
    "    # if you want to use loaded generator\n",
    "    generator_path = request('generator_path', 'peal_runs/cancer_tissue_generator/model.cpl')\n",
    "    generator = torch.load(generator_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use counterfactual know\n",
    "from peal.adaptors.counterfactual_knowledge_distillation import CounterfactualKnowledgeDistillation\n",
    "cal = CounterfactualKnowledgeDistillation(\n",
    "    student = student,\n",
    "    datasource = (poised_dataset_train, poised_dataset_val, unpoised_dataset_test),\n",
    "    output_size = 2,\n",
    "    generator = generator,\n",
    "    teacher = teacher,\n",
    "    base_dir = request(\n",
    "        'cfkd_base_dir',\n",
    "        'peal_runs/cancer_tissue_classifier/cfkd_' + teacher_type\n",
    "    ),\n",
    "    gigabyte_vram = gigabyte_vram / 2,\n",
    "    use_visualization = False\n",
    ")\n",
    "cal.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peal_env",
   "language": "python",
   "name": "peal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
