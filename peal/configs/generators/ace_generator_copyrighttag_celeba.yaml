'attention_resolutions' : '32,16,8'
'batch_size' : 50
'channel_mult' : ''
'chunk' : 0
'class_cond' : False
'classifier_scales' : '8,10,15'
'clip_denoised' : True
'base_path' : 'peal_runs/ddpm_copyrighttag_celeba_new'
'diffusion_steps' : 500
'dropout' : 0.0
'exp_name' : 'example_name'
'gpu' : '0'
'guided_iterations' : 9999999
'image_size' : 128
'l1_loss' : 0.05
'l2_loss' : 0.0
'l_perc' : 30.0
'l_perc_layer' : 18
'learn_sigma' : True
'merge_and_eval' : False
'noise_schedule' : 'linear'
'num_batches' : 1
'num_channels' : 128
'num_chunks' : 1
'num_head_channels' : -1
'num_heads' : 4
'num_heads_upsample' : -1
'num_res_blocks' : 2
# 'oracle_path' : '../dime2/oracle.pth'
'predict_xstart' : False
'resblock_updown' : True
'rescale_learned_sigmas' : False
'rescale_timesteps' : False
'sampling_scale' : 1.0
'save_images' : True
'save_x_t' : True
'save_z_t' : True
'seed' : 4
'start_step' : 60
'target_label' : -1
'timestep_respacing' : '200'
'use_checkpoint' : False
'use_ddim' : False
'use_fp16' : False
'use_kl' : False
'use_logits' : True
'use_new_attention_order' : False
'use_sampling_on_x_t' : True
'use_scale_shift_norm' : True
'use_train' : False
'method' : 'ace'
'num_samples' : 500000000000  # useful to sample few examples
'attack_method' : "PGD"  # Attack method (currently 'PGD', 'C&W', 'GD' and 'None' supported)
'attack_iterations' : 50  # Attack iterations updates
'attack_epsilon' : 255  # L inf epsilon bound (will be devided by 255)
'attack_step' : 1.0  # Attack update step (will be devided by 255)
'attack_joint' : True  # Set to false to generate adversarial attacks generation!
'attack_joint_checkpoint' : False
'attack_checkpoint_backward_steps' : 1 # Use dime2 shortcut to transfer gradients. We do not recommend it.
'attack_joint_shortcut' : False
'dist_l1' : 0.0  # l1 scaling factor
'dist_l2' : 1.0  # l2 scaling factor schedule for the distance loss. We did not used any for our results
'dist_schedule' : "none" # filtering args fraction of noise steps (e.g. 0.1 for 1000 smpling steps would be 100 out of 1000)
'sampling_time_fraction' : 0.1
'sampling_stochastic' : True  # Set to False to remove the noise when sampling
'sampling_inpaint' : 0.15  # Inpainting threshold
'sampling_dilation' : 15  # Dilation size for the mask generation
'label_query' : -1  # Query label to target
'label_target' : -1  # Target label, useful for MultiClass datasets
'chunks' : 1 # Chunking for spliting the CE generation into multiple gpus
'merge_chunks' : False  # to merge all chunked results
'cudnn_deterministic' : False  # to make the results deterministic
# own parameters
'max_train_steps' : 1000000
'data' : '<PEAL_BASE>/configs/data/copyrighttag_celeba.yaml'
'current_fid' : 100000000000000.0'
'best_fid' : 100000000000000.0'
'generator_type' : 'ddpm'
# from argparsing
'gpus' : ''
'schedule_sampler' : "uniform"
'microbatch' : -1
'ema_rate' : "0.9999"
'lr' : 0.0001
'weight_decay' : 0.0
'lr_anneal_steps' : 0
'log_interval' : 10
'save_interval' : 10000
'resume_checkpoint' : ""
'fp16_scale_growth' : 1e-3
'use_hdf5' : False